{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the target column is named 'target' and rest are features\n",
    "X = data.drop(columns='label')\n",
    "y = data['label']\n",
    "\n",
    "# Normalize/standardize features if necessary\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- X contains the features (independent variables).\n",
    "y contains the target variable (dependent variable).\n",
    "Normalization/standardization (commented out) ensures that all features contribute equally to the distance calculations in KNN. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining Train-Test Splits and K Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splits = [0.60, 0.70, 0.75, 0.80, 0.90, 0.95]\n",
    "k_values = [2, 4, 5, 6, 7, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Lists of different train-test splits and K values for KNN to be evaluated. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluating KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(X_train, X_test, y_train, y_test, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- A function to train and evaluate the KNN model:\n",
    "X_train, X_test, y_train, y_test: Training and testing data.\n",
    "k: The number of neighbors for KNN.\n",
    "Returns the accuracy and confusion matrix of the model. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Running the Evaluations and Storing Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# for split in train_test_splits:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split, random_state=42)\n",
    "#     for k in k_values:\n",
    "#         accuracy, conf_matrix = evaluate_knn(X_train, X_test, y_train, y_test, k)\n",
    "#         results[(split, k)] = (accuracy, conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- results: A dictionary to store the accuracy and confusion matrix for each combination of train-test split and K value.\n",
    "Loop through each train-test split, create training and testing sets, and evaluate the KNN model for each value of K.\n",
    "Store the results in the results dictionary. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Implementing One Scenario and Commenting Out the Rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9600793650793651\n",
      "Confusion Matrix:\n",
      "[[1197    0    0    0    0    0    3    0    0    0]\n",
      " [   0 1387    1    0    1    0    0    0    0    0]\n",
      " [  15   20 1240    3    1    1    1   10    3    0]\n",
      " [   1    6   15 1305    0    9    1    6    9    3]\n",
      " [   2   12    0    0 1190    0    4    3    0   11]\n",
      " [   1    3    0   36    4 1031    5    0    2    3]\n",
      " [  13    2    1    1    4    7 1228    0    0    0]\n",
      " [   0   24    9    0    3    1    0 1311    0   11]\n",
      " [   5   13   14   35    3   35    6    5 1085    8]\n",
      " [   8    4    1   16   36    3    0   38    2 1123]]\n"
     ]
    }
   ],
   "source": [
    "#  Example scenario\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "accuracy, conf_matrix = evaluate_knn(X_train, X_test, y_train, y_test, 2)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# Full implementation is commented out to avoid long runtime\n",
    "# for split in train_test_splits:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split, random_state=42)\n",
    "#     for k in k_values:\n",
    "#         accuracy, conf_matrix = evaluate_knn(X_train, X_test, y_train, y_test, k)\n",
    "#         results[(split, k)] = (accuracy, conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Example scenario for train-test split of 0.60 and K=2. The rest of the scenarios are commented out to demonstrate a single case. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Saving Results to a PDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Creates a PDF file named knn_results.pdf to store the confusion matrices and accuracy scores.\n",
    "For each combination of train-test split and K value:\n",
    "Creates a plot of the confusion matrix.\n",
    "Annotates the plot with accuracy and confusion matrix values.\n",
    "Saves the plot to the PDF. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for all the values\n",
    "# pdf = matplotlib.backends.backend_pdf.PdfPages(\"knn_results.pdf\")\n",
    "\n",
    "# for key, value in results.items():\n",
    "#     split, k = key\n",
    "#     accuracy, conf_matrix = value\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "#     for i in range(conf_matrix.shape[0]):\n",
    "#         for j in range(conf_matrix.shape[1]):\n",
    "#             ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.title(f\"Train-Test Split: {split}, K: {k}\\nAccuracy: {accuracy:.2f}\")\n",
    "#     pdf.savefig(fig)\n",
    "#     plt.close()\n",
    "\n",
    "# pdf.close()-->for all the values\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"knn_results1.pdf\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title(f\"Train-Test Split: {0.3}, K: {2}\\nAccuracy: {accuracy:.2f}\")\n",
    "pdf.savefig(fig)\n",
    "plt.close()\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "### Creating a Plot\n",
    "\n",
    "```python\n",
    "    fig, ax = plt.subplots()\n",
    "```\n",
    "- This line creates a new figure and axes object using Matplotlib's `subplots` function. \n",
    "- `fig` is the figure object, and `ax` is the axes object where the confusion matrix will be plotted.\n",
    "\n",
    "### Plotting the Confusion Matrix\n",
    "\n",
    "```python\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "```\n",
    "- This line plots the confusion matrix on the axes `ax` using the `matshow` function.\n",
    "- `conf_matrix` is the matrix to be plotted.\n",
    "- `cmap=plt.cm.Blues` specifies the color map to use, in this case, shades of blue.\n",
    "- `alpha=0.3` sets the transparency level of the plot.\n",
    "\n",
    "### Annotating the Plot\n",
    "\n",
    "```python\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "```\n",
    "- This nested loop iterates over each cell in the confusion matrix.\n",
    "- `conf_matrix.shape[0]` gives the number of rows, and `conf_matrix.shape[1]` gives the number of columns.\n",
    "- `ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')` adds text annotations to each cell:\n",
    "  - `x=j` and `y=i` specify the position of the text.\n",
    "  - `s=conf_matrix[i, j]` specifies the text to display, which is the value in the confusion matrix at position (i, j).\n",
    "  - `va='center'` and `ha='center'` center the text vertically and horizontally within the cell.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Initialize PDF**: Create a `PdfPages` object to handle multiple pages in a PDF.\n",
    "- **Iterate Results**: Loop through each result (train-test split and K value).\n",
    "- **Extract Values**: Get the specific train-test split, K value, accuracy, and confusion matrix.\n",
    "- **Create Plot**: Initialize a new plot.\n",
    "- **Plot Confusion Matrix**: Visualize the confusion matrix with colors.\n",
    "- **Annotate Plot**: Add text to each cell of the confusion matrix.\n",
    "- **Labels and Title**: Add axis labels and a title to the plot.\n",
    "- **Save Plot**: Save the current plot to the PDF.\n",
    "- **Close Plot**: Close the plot to free memory.\n",
    "- **Finalize PDF**: Close the PDF file after all plots are saved. --> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Analysis of Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The performance of the KNN model depends on both the train-test split and the value of K. Generally, a higher proportion of training data can lead to better model performance due to more information being available for the model to learn from. However, this may also lead to overfitting if the test set is too small. The value of K also plays a crucial role, with too small a K value leading to high variance and too large a K value leading to high bias. The optimal value of K often lies between 5 and 10, balancing bias and variance effectively.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis = \"\"\"\n",
    "The performance of the KNN model depends on both the train-test split and the value of K. Generally, a higher proportion of training data can lead to better model performance due to more information being available for the model to learn from. However, this may also lead to overfitting if the test set is too small. The value of K also plays a crucial role, with too small a K value leading to high variance and too large a K value leading to high bias. The optimal value of K often lies between 5 and 10, balancing bias and variance effectively.\n",
    "\"\"\"\n",
    "\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
